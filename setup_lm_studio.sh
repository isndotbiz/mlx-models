#!/bin/bash
# LM Studio Setup Script for M4 Pro + MLX Models
# Creates optimal configuration for 16GB unified memory

set -e

echo "üöÄ LM STUDIO OPTIMIZATION SETUP"
echo "================================"
echo ""

# Colors
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Check if LM Studio is installed
if [ ! -d "/Applications/LM Studio.app" ]; then
    echo "‚ùå LM Studio not found at /Applications/LM Studio.app"
    echo "Please install LM Studio first: https://lmstudio.ai"
    exit 1
fi

echo -e "${GREEN}‚úì${NC} LM Studio found"

# Bootstrap CLI if not already done
echo ""
echo "üì¶ Bootstrapping LM Studio CLI..."
~/.lmstudio/bin/lms bootstrap 2>/dev/null || true
echo -e "${GREEN}‚úì${NC} CLI ready"

# Check for RAG plugin
echo ""
echo "üîå Checking LM Studio extensions..."
if [ -d ~/.lmstudio/hub/rag-v1 ]; then
    echo -e "${GREEN}‚úì${NC} RAG plugin installed"
else
    echo -e "${YELLOW}‚ö†${NC}  RAG plugin not found"
    echo "Would you like to install it? (y/n)"
    read -r response
    if [[ "$response" =~ ^([yY][eE][sS]|[yY])$ ]]; then
        echo "Installing RAG plugin..."
        cd ~/.lmstudio/hub
        ~/.lmstudio/bin/lms clone lmstudio/rag-v1
        echo -e "${GREEN}‚úì${NC} RAG plugin installed"
    fi
fi

# Check model directory
echo ""
echo "üìÅ Verifying model directory..."
MODEL_DIR="/Users/jonathanmallinger/models/mlx"
if [ -d "$MODEL_DIR" ]; then
    MODEL_COUNT=$(ls -1 "$MODEL_DIR" | wc -l | tr -d ' ')
    echo -e "${GREEN}‚úì${NC} Found $MODEL_COUNT models in $MODEL_DIR"
else
    echo -e "${YELLOW}‚ö†${NC}  Model directory not found: $MODEL_DIR"
fi

# Launch LM Studio
echo ""
echo "üöÄ Opening LM Studio..."
open "/Applications/LM Studio.app"

# Wait a moment for app to start
sleep 2

# Display configuration instructions
cat << 'EOF'

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                   LM STUDIO CONFIGURATION GUIDE                    ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

üîß CRITICAL SETTINGS (Must Configure):
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

1Ô∏è‚É£  SET MLX ENGINE (MOST IMPORTANT!)
   üìç Settings ‚Üí Inference ‚Üí Engine
   ‚úì Select: "MLX (Apple Silicon GPU)"
   ‚ùå Don't use: llama.cpp (slower on Mac)

2Ô∏è‚É£  ADD MODEL PATH
   üìç Settings ‚Üí Models ‚Üí Local Model Folders
   ‚úì Click "Add Folder"
   ‚úì Select: /Users/jonathanmallinger/models/mlx
   ‚úì Your 9 verified models will now appear!

3Ô∏è‚É£  ENABLE OPTIMIZATIONS
   üìç Settings ‚Üí Inference
   ‚úì Flash Attention: ON (if available)
   ‚úì Metal Acceleration: ON (automatic)
   ‚úì GPU Offload: Maximum layers

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
‚öôÔ∏è  RECOMMENDED SETTINGS PER MODEL:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìä SMALL MODELS (1-4B):
   ‚Ä¢ Context: 8192-16384 tokens
   ‚Ä¢ Temperature: 0.7
   ‚Ä¢ Top-P: 0.9
   ‚Ä¢ Use for: Fast queries, development

üìä MEDIUM MODELS (7-8B):
   ‚Ä¢ Context: 4096-8192 tokens
   ‚Ä¢ Temperature: 0.7
   ‚Ä¢ Top-P: 0.9
   ‚Ä¢ Use for: Balanced tasks

üìä LARGE MODELS (14B):
   ‚Ä¢ Context: 4096 tokens (recommended)
   ‚Ä¢ Temperature: 0.7
   ‚Ä¢ Top-P: 0.9
   ‚Ä¢ Close other apps for best performance

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
‚úÖ YOUR VERIFIED MODELS:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

‚ö° FAST (Interactive):
   ‚Ä¢ Josiefied-Qwen3-1.7B-abliterated-v1-4bit     (92 t/s)
   ‚Ä¢ DeepSeek-R1-Distill-Qwen-1.5B-3bit            (84 t/s)
   ‚Ä¢ Qwen3-4B-4bit                                 (47 t/s)

üéØ STANDARD (Balanced):
   ‚Ä¢ mistral-7b                                    (33 t/s)
   ‚Ä¢ dolphin3-8b                                   (17 t/s)
   ‚Ä¢ qwen3-7b                                      (13 t/s)

üéì SPECIALIZED:
   ‚Ä¢ WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B-mlx     (Security)
   ‚Ä¢ Josiefied-Qwen3-8B-abliterated-v1-4bit       (Uncensored)
   ‚Ä¢ Josiefied-Qwen3-14B-abliterated-v3-6bit      (Most capable)

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üí° PRO TIPS:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

1. First generation is slow (MLX compilation)
   ‚Üí Send a "hello" message to warm up the model
   ‚Üí Subsequent generations are much faster

2. Memory management (24GB M4 Pro):
   ‚Üí Can run 1-2 models comfortably
   ‚Üí Close other apps when using 14B model

3. Context length affects speed:
   ‚Üí Shorter context = faster generation
   ‚Üí Use 4K-8K for interactive work
   ‚Üí Use 16K+ only when needed

4. Model selection:
   ‚Üí Start with small/fast models
   ‚Üí Escalate to larger models if quality insufficient
   ‚Üí 1.7B ‚Üí 4B ‚Üí 8B ‚Üí 14B (quality progression)

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üîå INSTALLED EXTENSIONS:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

‚úì RAG v1 (Retrieval Augmented Generation)
  ‚Üí Enable in LM Studio ‚Üí Extensions
  ‚Üí Allows uploading documents for context

To develop RAG plugin:
  cd ~/.lmstudio/hub/rag-v1
  ~/.lmstudio/bin/lms dev

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üìö DOCUMENTATION:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

View full model details:
  cat /Users/jonathanmallinger/models/VERIFIED_MODELS.md

View use case guide:
  cat /Users/jonathanmallinger/models/MODEL_USE_CASES.md

Test a model from command line:
  cd /Users/jonathanmallinger/models
  source .venv/bin/activate
  python3 test_model.py ./mlx/MODEL_NAME

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üéâ Setup complete! Load a model and start chatting!

Remember to:
1. Set engine to MLX (Settings ‚Üí Inference ‚Üí Engine)
2. Add model path (Settings ‚Üí Models ‚Üí Local Model Folders)
3. Warm up model with test message after loading

Happy prompting! üöÄ

EOF

echo ""
echo -e "${GREEN}‚úì${NC} Setup script complete!"
echo ""
