# Speculative Decoding Quick Reference

## ğŸš€ Quick Start

```bash
# Run complete test suite
python test_speculative_complete.py

# Check results
cat test_results.json
```

## ğŸ“Š What Gets Measured

| Test Type | What It Shows |
|-----------|---------------|
| **Configuration** | Baseline vs 3/5/7 draft tokens |
| **Prompt Types** | Which tasks benefit most |
| **System Prompts** | Quality vs performance tradeoff |
| **Speedup** | Percentage improvement |

## ğŸ¯ Expected Results

### Typical Speedup
- **No speculative**: Baseline (18-22 tok/s)
- **3 tokens**: +25-35% speedup
- **5 tokens**: +40-65% speedup â­ **OPTIMAL**
- **7 tokens**: +30-55% speedup

### Best Use Cases (highest speedup)
1. ğŸ† Technical explanations
2. ğŸ’» Code generation
3. ğŸ”’ Security queries
4. ğŸ¨ Creative tasks (lower benefit)

## ğŸ“ Output Files

| File | Contains |
|------|----------|
| `test_results.json` | Full metrics and recommendations |
| `test_speculative_complete.py` | Test script |
| `TESTING_GUIDE.md` | Detailed documentation |

## ğŸ”§ Common Commands

```bash
# Install dependencies
pip install requests rich

# Make executable
chmod +x test_speculative_complete.py

# Run tests
./test_speculative_complete.py

# Check if server is running
lsof -i :8000
```

## âš¡ Performance Checklist

- [ ] Server responds on port 8000
- [ ] Baseline performance > 15 tok/s
- [ ] Speculative speedup > 30%
- [ ] No connection errors
- [ ] Results saved to JSON

## ğŸ¨ Visual Output

### With `rich` (recommended)
- âœ¨ Beautiful tables
- ğŸ¨ Color-coded results
- ğŸ“Š Progress bars
- ğŸ“¦ Formatted panels

### Without `rich`
- âœ… Plain text tables
- ğŸ“ Simple formatting
- âœ“ Still fully functional

## ğŸ“ˆ Interpreting Results

### Excellent (50-70% speedup)
âœ… Configuration is optimal
âœ… Models are well-matched
âœ… Use in production

### Good (30-50% speedup)
âœ… Working correctly
âœ… Try adjusting draft tokens
âœ… Safe for production

### Poor (0-30% speedup)
âš ï¸ Check model compatibility
âš ï¸ Verify GPU utilization
âš ï¸ Consider different draft model

### Negative speedup
âŒ Overhead too high
âŒ Disable speculative decoding
âŒ Use baseline instead

## ğŸ” Troubleshooting

| Issue | Solution |
|-------|----------|
| Server not found | Start with `python test_speculative.py` |
| Connection timeout | Check firewall/ports |
| Low performance | Close other apps, check GPU |
| Import errors | `pip install requests rich` |
| Permission denied | `chmod +x test_speculative_complete.py` |

## ğŸ“‹ Test Sections

### 1. Server Status âœ“
Checks if servers are running and responsive

### 2. Configuration Tests âš™ï¸
Tests baseline vs 3/5/7 draft tokens

### 3. Prompt Type Tests ğŸ“
Measures speedup for different tasks

### 4. System Prompt Tests ğŸ’¬
Compares different prompt strategies

### 5. Report Generation ğŸ“Š
Creates JSON with all metrics

### 6. Recommendations ğŸ¯
Suggests optimal configuration

## ğŸ¯ Action Items

After running tests:

1. âœ… Note recommended configuration
2. âœ… Update server startup script
3. âœ… Test with real workload
4. âœ… Monitor production performance
5. âœ… Save results for comparison

## ğŸ“Š Sample Output

```
ğŸ† Recommended Configuration: 5 draft tokens
   Performance: 29.8 tokens/sec
   Speedup: +64% vs baseline

ğŸ’¡ Best Use Case: Technical explanation
   Achieves +67% speedup
```

## ğŸš€ Production Setup

Use optimal settings found:

```bash
python -m vllm.entrypoints.openai.api_server \
    --model deepseek-ai/DeepSeek-R1-Distill-Qwen-7B \
    --speculative-model Qwen/Qwen2.5-1.5B-Instruct \
    --num-speculative-tokens 5 \
    --use-v2-block-manager
```

## ğŸ“ Need Help?

1. Check `TESTING_GUIDE.md` for details
2. Review `example_test_output.txt` for expected output
3. Examine `example_test_results.json` for sample data
4. Verify server logs for errors

## ğŸ’¡ Pro Tips

- âœ¨ Run tests after model updates
- ğŸ“Š Compare results over time
- ğŸ¯ Test with your actual prompts
- âš¡ 5 tokens usually optimal
- ğŸ”„ Re-test after config changes

---

**Remember**: Speculative decoding trades slight accuracy for speed. Perfect for production where speed matters!
